import streamlit as st
import requests
import json
import re

st.set_page_config(page_title="Walidator Wniosk√≥w", page_icon="üìã", layout="wide")

OLLAMA_HOST = "http://ollama:11434"
DEFAULT_MODEL = "gpt-oss:120b"
ALTERNATIVE_MODEL = "gpt-oss:20b"

st.title("üìã Walidator Wniosk√≥w Grantowych")
st.markdown("Narzƒôdzie do wstƒôpnej oceny zgodno≈õci projektu z profilem instytutu oraz potencja≈Çem komercjalizacyjnym.")

# Sidebar for settings
with st.sidebar:
    st.header("Settings")
    try:
        response = requests.get(f"{OLLAMA_HOST}/api/tags")
        if response.status_code == 200:
            models = [m['name'] for m in response.json().get('models', [])]
            
            # Ensure our target models are in the list
            if DEFAULT_MODEL not in models:
                 models.append(DEFAULT_MODEL)
            if ALTERNATIVE_MODEL not in models:
                 models.append(ALTERNATIVE_MODEL)
            
            # Sort to keep our preferred models at the top
            models.sort(key=lambda x: (x != DEFAULT_MODEL, x != ALTERNATIVE_MODEL))
            
            selected_model = st.selectbox("Select Model", models)
        else:
            st.error("Could not fetch models from Ollama.")
            selected_model = DEFAULT_MODEL
    except Exception as e:
        st.error(f"Connection error: {e}")
        selected_model = DEFAULT_MODEL
    
    st.markdown("---")
    st.markdown(f"- Active Model: `{selected_model}`")

# --- INPUT FORM ---
with st.container():
    c1, c2 = st.columns([1, 1])
    
    with c1:
        st.subheader("1. Profil Instytutu")
        institute_profile = st.text_area(
            "Opisz profil dzia≈Çalno≈õci badawczej i kompetencje instytutu:",
            height=300,
            placeholder="Np. Instytut specjalizuje siƒô w badaniach nad sztucznƒÖ inteligencjƒÖ, uczeniem maszynowym oraz ich zastosowaniem w medycynie..."
        )

    with c2:
        st.subheader("2. Dane Projektu")
        project_goal = st.text_area("Cel projektu (kr√≥tki opis):", height=100)
        innovations = st.text_area("G≈Ç√≥wne funkcjonalno≈õci / Cechy innowacyjne:", height=100, help="Elementy innowacyjne lub znaczƒÖco ulepszone w stosunku do rynku.")
        results = st.text_area("Rezultaty:", height=100, help="Mierzalne efekty, w tym komercjalizacja.")

# --- VALIDATION LOGIC ---
if st.button("Sprawd≈∫ Wniosek (GO / NO-GO)", type="primary"):
    if not all([institute_profile, project_goal, innovations, results]):
        st.error("Proszƒô wype≈Çniƒá wszystkie pola formularza.")
    else:
        with st.spinner("Analizujƒô wniosek (model 120B)..."):
            # Construct the Prompt
            prompt = f"""
Jeste≈õ surowym i precyzyjnym ekspertem oceniajƒÖcym wnioski grantowe. Twoim zadaniem jest ocena projektu na podstawie dostarczonych danych pod kƒÖtem dw√≥ch kryteri√≥w krytycznych.

DANE WEJ≈öCIOWE:
1. PROFIL INSTYTUTU:
{institute_profile}

2. CEL PROJEKTU:
{project_goal}

3. INNOWACJE:
{innovations}

4. REZULTATY:
{results}

KRYTERIA OCENY:
1. DOPASOWANIE DO PROFILU: Czy projekt mie≈õci siƒô w obszarze badawczym i kompetencyjnym instytutu? Je≈õli projekt pasowa≈Çby lepiej do innego typu instytutu, nale≈ºy to wypunktowaƒá.
2. KOMERCJALIZACJA: Czy wyniki prowadzƒÖ do rynkowej komercjalizacji (sprzeda≈º, licencja), czy jest to tylko "wdro≈ºenie w≈Çasne" lub realizacja potrzeb wewnƒôtrznych (co jest b≈Çƒôdem)? Projekt musi mieƒá potencja≈Ç rynkowy.

WYMAGANY FORMAT ODPOWIEDZI:
Analizƒô przedstaw w punktach, a na ko≈Ñcu wydaj jednoznacznƒÖ opiniƒô.

### 1. Analiza Zgodno≈õci z Profilem
(Twoja analiza...)

### 2. Analiza Potencja≈Çu Komercjalizacyjnego
(Twoja analiza - zwr√≥ƒá uwagƒô czy to nie jest wdro≈ºenie wewnƒôtrzne...)

### WERDYKT KO≈ÉCOWY
**[GO / NO-GO]**

### UZASADNIENIE
(Kr√≥tkie, ≈ºo≈Çnierskie uzasadnienie decyzji. Je≈õli NO-GO, napisz dlaczego.)
"""
            
            # Send to Ollama
            payload = {
                "model": selected_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.2, # Low temperature for consistent, strict evaluation
                    "num_ctx": 4096
                }
            }
            
            try:
                response = requests.post(f"{OLLAMA_HOST}/api/generate", json=payload)
                if response.status_code == 200:
                    result_text = response.json().get('response', '')
                    
                    # Display Results
                    st.markdown("---")
                    st.subheader("Wynik Analizy AI")
                    st.markdown(result_text)
                    
                    # Visual feedback based on verdict
                    # CRITICAL: Only search for verdict in the WERDYKT section to avoid false positives
                    # from Polish words containing "GO" like "DIALOG", "LOGO", "KATEGORIA"
                    verdict_section = ""
                    werdykt_match = re.search(r'WERDYKT[^\n]*\n([\s\S]{0,100})', result_text, re.IGNORECASE)
                    if werdykt_match:
                        verdict_section = werdykt_match.group(0)
                    else:
                        # Fallback: check last 200 characters
                        verdict_section = result_text[-200:]
                    
                    # Now search for verdict ONLY in the extracted section
                    if re.search(r'NO[- _]?GO', verdict_section, re.IGNORECASE):
                        st.error("WERDYKT: NO-GO üõë")
                    elif re.search(r'\*\*GO\*\*|\bGO\b', verdict_section, re.IGNORECASE):
                        st.success("WERDYKT: GO ‚úÖ")
                    else:
                        st.warning("‚ö†Ô∏è Nie uda≈Ço siƒô automatycznie wykryƒá werdyktu (sprawd≈∫ tekst analizy).")
                    
                else:
                    st.error(f"B≈ÇƒÖd komunikacji z modelem: {response.text}")
            except Exception as e:
                st.error(f"WystƒÖpi≈Ç b≈ÇƒÖd: {e}")
