import streamlit as st
import requests
import json

st.set_page_config(page_title="Walidator WnioskÃ³w", page_icon="ðŸ“‹", layout="wide")

OLLAMA_HOST = "http://ollama:11434"
DEFAULT_MODEL = "gpt-oss:120b"
ALTERNATIVE_MODEL = "gpt-oss:20b"

st.title("ðŸ“‹ Walidator WnioskÃ³w Grantowych")
st.markdown("NarzÄ™dzie do wstÄ™pnej oceny zgodnoÅ›ci projektu z profilem instytutu oraz potencjaÅ‚em komercjalizacyjnym.")

# Sidebar for settings
with st.sidebar:
    st.header("Settings")
    try:
        response = requests.get(f"{OLLAMA_HOST}/api/tags")
        if response.status_code == 200:
            models = [m['name'] for m in response.json().get('models', [])]
            
            # Ensure our target models are in the list
            if DEFAULT_MODEL not in models:
                 models.append(DEFAULT_MODEL)
            if ALTERNATIVE_MODEL not in models:
                 models.append(ALTERNATIVE_MODEL)
            
            # Sort to keep our preferred models at the top
            models.sort(key=lambda x: (x != DEFAULT_MODEL, x != ALTERNATIVE_MODEL))
            
            selected_model = st.selectbox("Select Model", models)
        else:
            st.error("Could not fetch models from Ollama.")
            selected_model = DEFAULT_MODEL
    except Exception as e:
        st.error(f"Connection error: {e}")
        selected_model = DEFAULT_MODEL
    
    st.markdown("---")
    st.markdown(f"- Active Model: `{selected_model}`")

# --- INPUT FORM ---
with st.container():
    c1, c2 = st.columns([1, 1])
    
    with c1:
        st.subheader("1. Profil Instytutu")
        institute_profile = st.text_area(
            "Opisz profil dziaÅ‚alnoÅ›ci badawczej i kompetencje instytutu:",
            height=300,
            placeholder="Np. Instytut specjalizuje siÄ™ w badaniach nad sztucznÄ… inteligencjÄ…, uczeniem maszynowym oraz ich zastosowaniem w medycynie..."
        )

    with c2:
        st.subheader("2. Dane Projektu")
        project_goal = st.text_area("Cel projektu (krÃ³tki opis):", height=100)
        innovations = st.text_area("GÅ‚Ã³wne funkcjonalnoÅ›ci / Cechy innowacyjne:", height=100, help="Elementy innowacyjne lub znaczÄ…co ulepszone w stosunku do rynku.")
        results = st.text_area("Rezultaty:", height=100, help="Mierzalne efekty, w tym komercjalizacja.")

# --- VALIDATION LOGIC ---
if st.button("SprawdÅº Wniosek (GO / NO-GO)", type="primary"):
    if not all([institute_profile, project_goal, innovations, results]):
        st.error("ProszÄ™ wypeÅ‚niÄ‡ wszystkie pola formularza.")
    else:
        with st.spinner("AnalizujÄ™ wniosek (model 120B)..."):
            # Construct the Prompt
            prompt = f"""
JesteÅ› surowym i precyzyjnym ekspertem oceniajÄ…cym wnioski grantowe. Twoim zadaniem jest ocena projektu na podstawie dostarczonych danych pod kÄ…tem dwÃ³ch kryteriÃ³w krytycznych.

DANE WEJÅšCIOWE:
1. PROFIL INSTYTUTU:
{institute_profile}

2. CEL PROJEKTU:
{project_goal}

3. INNOWACJE:
{innovations}

4. REZULTATY:
{results}

KRYTERIA OCENY:
1. DOPASOWANIE DO PROFILU: Czy projekt mieÅ›ci siÄ™ w obszarze badawczym i kompetencyjnym instytutu? JeÅ›li projekt pasowaÅ‚by lepiej do innego typu instytutu, naleÅ¼y to wypunktowaÄ‡.
2. KOMERCJALIZACJA: Czy wyniki prowadzÄ… do rynkowej komercjalizacji (sprzedaÅ¼, licencja), czy jest to tylko "wdroÅ¼enie wÅ‚asne" lub realizacja potrzeb wewnÄ™trznych (co jest bÅ‚Ä™dem)? Projekt musi mieÄ‡ potencjaÅ‚ rynkowy.

WYMAGANY FORMAT ODPOWIEDZI:
AnalizÄ™ przedstaw w punktach, a na koÅ„cu wydaj jednoznacznÄ… opiniÄ™.

### 1. Analiza ZgodnoÅ›ci z Profilem
(Twoja analiza...)

### 2. Analiza PotencjaÅ‚u Komercjalizacyjnego
(Twoja analiza - zwrÃ³Ä‡ uwagÄ™ czy to nie jest wdroÅ¼enie wewnÄ™trzne...)

### WERDYKT KOÅƒCOWY
**[GO / NO-GO]**

### UZASADNIENIE
(KrÃ³tkie, Å¼oÅ‚nierskie uzasadnienie decyzji. JeÅ›li NO-GO, napisz dlaczego.)
"""
            
            # Send to Ollama
            payload = {
                "model": selected_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.2, # Low temperature for consistent, strict evaluation
                    "num_ctx": 4096
                }
            }
            
            try:
                response = requests.post(f"{OLLAMA_HOST}/api/generate", json=payload)
                if response.status_code == 200:
                    result_text = response.json().get('response', '')
                    
                    # Display Results
                    st.markdown("---")
                    st.subheader("Wynik Analizy AI")
                    st.markdown(result_text)
                    
                    # Visual feedback based on verdict
                    if "NO-GO" in result_text.upper():
                        st.error("WERDYKT: NO-GO ðŸ›‘")
                    elif "GO" in result_text.upper():
                        st.success("WERDYKT: GO âœ…")
                    
                else:
                    st.error(f"BÅ‚Ä…d komunikacji z modelem: {response.text}")
            except Exception as e:
                st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d: {e}")
