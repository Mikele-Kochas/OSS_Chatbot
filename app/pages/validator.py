import streamlit as st
import requests
import json
import re

st.set_page_config(page_title="Walidator Wniosk√≥w", page_icon="üìã", layout="wide")

OLLAMA_HOST = "http://ollama:11434"
DEFAULT_MODEL = "gpt-oss:120b"
ALTERNATIVE_MODEL = "gpt-oss:20b"

st.title("üìã Walidator Wniosk√≥w Grantowych")
st.markdown("Narzƒôdzie do wstƒôpnej oceny zgodno≈õci projektu z profilem instytutu oraz potencja≈Çem komercjalizacyjnym.")

# Sidebar for settings
with st.sidebar:
    st.header("Settings")
    try:
        response = requests.get(f"{OLLAMA_HOST}/api/tags")
        if response.status_code == 200:
            models = [m['name'] for m in response.json().get('models', [])]
            
            # Ensure our target models are in the list
            if DEFAULT_MODEL not in models:
                 models.append(DEFAULT_MODEL)
            if ALTERNATIVE_MODEL not in models:
                 models.append(ALTERNATIVE_MODEL)
            
            # Sort to keep our preferred models at the top
            models.sort(key=lambda x: (x != DEFAULT_MODEL, x != ALTERNATIVE_MODEL))
            
            selected_model = st.selectbox("Select Model", models)
        else:
            st.error("Could not fetch models from Ollama.")
            selected_model = DEFAULT_MODEL
    except Exception as e:
        st.error(f"Connection error: {e}")
        selected_model = DEFAULT_MODEL
    
    st.markdown("---")
    st.markdown(f"- Active Model: `{selected_model}`")

# --- INPUT FORM ---
with st.container():
    c1, c2 = st.columns([1, 1])
    
    with c1:
        st.subheader("1. Profil Instytutu")
        institute_profile = st.text_area(
            "Opisz profil dzia≈Çalno≈õci badawczej i kompetencje instytutu:",
            height=300,
            placeholder="Np. Instytut specjalizuje siƒô w badaniach nad sztucznƒÖ inteligencjƒÖ, uczeniem maszynowym oraz ich zastosowaniem w medycynie..."
        )

    with c2:
        st.subheader("2. Dane Projektu")
        project_goal = st.text_area("Cel projektu (kr√≥tki opis):", height=100)
        innovations = st.text_area("G≈Ç√≥wne funkcjonalno≈õci / Cechy innowacyjne:", height=100, help="Elementy innowacyjne lub znaczƒÖco ulepszone w stosunku do rynku.")
        results = st.text_area("Rezultaty:", height=100, help="Mierzalne efekty, w tym komercjalizacja.")

# --- VALIDATION LOGIC ---
if st.button("Sprawd≈∫ Wniosek (GO / NO-GO)", type="primary"):
    if not all([institute_profile, project_goal, innovations, results]):
        st.error("Proszƒô wype≈Çniƒá wszystkie pola formularza.")
    else:
        with st.spinner(f"Analizujƒô wniosek ({selected_model})..."):
            # Construct the Prompt - JSON OUTPUT FORMAT
            prompt = f"""Jeste≈õ surowym i precyzyjnym ekspertem oceniajƒÖcym wnioski grantowe. Twoim zadaniem jest ocena projektu na podstawie dostarczonych danych pod kƒÖtem dw√≥ch kryteri√≥w krytycznych.

DANE WEJ≈öCIOWE:
1. PROFIL INSTYTUTU:
{institute_profile}

2. CEL PROJEKTU:
{project_goal}

3. INNOWACJE:
{innovations}

4. REZULTATY:
{results}

KRYTERIA OCENY:
1. DOPASOWANIE DO PROFILU: Czy projekt mie≈õci siƒô w obszarze badawczym i kompetencyjnym instytutu?
2. KOMERCJALIZACJA: Czy wyniki prowadzƒÖ do rynkowej komercjalizacji (sprzeda≈º, licencja), a nie tylko "wdro≈ºenia w≈Çasnego"?

ODPOWIEDZ W FORMACIE JSON (i TYLKO JSON, bez ≈ºadnego innego tekstu):
{{
  "analiza_profilu": "Twoja analiza zgodno≈õci z profilem instytutu...",
  "analiza_komercjalizacji": "Twoja analiza potencja≈Çu komercjalizacyjnego...",
  "werdykt": "GO",
  "uzasadnienie": "Kr√≥tkie uzasadnienie decyzji..."
}}

WA≈ªNE:
- Pole "werdykt" MUSI zawieraƒá DOK≈ÅADNIE jedno z dw√≥ch s≈Ç√≥w: "GO" lub "NO-GO" (wielkimi literami, bez innych znak√≥w).
- Odpowiedz TYLKO poprawnym JSON-em, bez ≈ºadnych dodatkowych komentarzy przed ani po.

Przyk≈Çad poprawnej odpowiedzi dla projektu kt√≥ry NIE pasuje:
{{
  "analiza_profilu": "Projekt dotyczy rolnictwa, co nie jest w profilu instytutu IT.",
  "analiza_komercjalizacji": "Brak planu sprzeda≈ºy, tylko wdro≈ºenie wewnƒôtrzne.",
  "werdykt": "NO-GO",
  "uzasadnienie": "Projekt nie pasuje do profilu i nie ma potencja≈Çu komercyjnego."
}}
"""
            
            # Send to Ollama with JSON format hint
            payload = {
                "model": selected_model,
                "prompt": prompt,
                "stream": False,
                "format": "json",  # Ollama hint for JSON output
                "options": {
                    "temperature": 0.1,
                    "num_ctx": 4096
                }
            }
            
            try:
                response = requests.post(f"{OLLAMA_HOST}/api/generate", json=payload)
                if response.status_code == 200:
                    result_text = response.json().get('response', '')
                    
                    # Try to parse JSON response
                    try:
                        result_json = json.loads(result_text)
                        
                        # Display Results
                        st.markdown("---")
                        st.subheader("Wynik Analizy AI")
                        
                        st.markdown("### 1. Analiza Zgodno≈õci z Profilem")
                        st.markdown(result_json.get("analiza_profilu", "Brak danych"))
                        
                        st.markdown("### 2. Analiza Potencja≈Çu Komercjalizacyjnego")
                        st.markdown(result_json.get("analiza_komercjalizacji", "Brak danych"))
                        
                        st.markdown("### WERDYKT KO≈ÉCOWY")
                        verdict = result_json.get("werdykt", "").strip().upper()
                        
                        st.markdown("### UZASADNIENIE")
                        st.markdown(result_json.get("uzasadnienie", "Brak uzasadnienia"))
                        
                        # Visual feedback based on EXACT verdict value
                        if verdict == "NO-GO":
                            st.error("WERDYKT: NO-GO üõë")
                        elif verdict == "GO":
                            st.success("WERDYKT: GO ‚úÖ")
                        else:
                            st.warning(f"‚ö†Ô∏è Nieoczekiwany werdykt: '{verdict}' (oczekiwano 'GO' lub 'NO-GO')")
                            
                    except json.JSONDecodeError:
                        # Fallback: display raw text if JSON parsing fails
                        st.warning("‚ö†Ô∏è Model nie zwr√≥ci≈Ç poprawnego JSON. Wy≈õwietlam surowƒÖ odpowied≈∫:")
                        st.markdown(result_text)
                        st.error("Nie uda≈Ço siƒô automatycznie wykryƒá werdyktu.")
                    
                else:
                    st.error(f"B≈ÇƒÖd komunikacji z modelem: {response.text}")
            except Exception as e:
                st.error(f"WystƒÖpi≈Ç b≈ÇƒÖd: {e}")

